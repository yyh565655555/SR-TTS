# SR-TTS
code for SR-TTS: a rhyme-based end-to-end speech synthesis system
https://doi.org/10.3389/fnbot.2024.1322312
Question:
FastSpeech series is also considered to be a very classic and practical model in the field of TTS (text2speech), the magic transformation of the article is also a lot, so where is the motivation for proposing this paper? At the beginning of learning FastSpeech2 code (https://github.com/ming024/FastSpeech2), the first step of preprocessing will be carried out in this step (prepare_align.py) of the alignment operation, in fact, it is also very good to understand that the essence of TTS is to do the syllables in each text (a little bit of strict called) and the corresponding phoneme. The essence of TTS is to make a mapping relationship between each text syllable (strictly called phoneme) and the corresponding Mel's spectrogram of the speech, that is to say, the model learns a continuous alignment process, then the problem arises, in order to model faster and better learning we force the text and speech to be aligned, so for both text and speech the original timing information is discarded, how to make up for this timing information in this task is our concern. How to make up this timing information in this generation task is the concern of our work.
Solution:
Since the timing information is lost, it is natural to think of replacing the timing module in the model. In the original FastSpeech2 structure, the Variance Adaptor plays a key role, which is responsible for adjusting the pitch, duration, and energy of the synthesized speech to improve the naturalness and expressiveness of the synthesized speech. It is responsible for adjusting the pitch, duration and energy of the synthesized speech to improve the naturalness and expressiveness of the synthesized speech. This layer is between the encoder and decoder, and the encoding and decoding has a fixed structure, this module is selected in the Variance Adaptor, of course, the duration is still necessary to put in the front first, the timing is of course preferred to consider the lstm, which is the reason for the inclusion of the prosody model, and the original prediction module of the Variance Adaptor is used to adjust the pitch, duration and energy. The original prediction module of Variance Adaptor is an ordinary convolutional layer, and it is natural to think of adding attention to improve the global information, and these are the innovative methods.

Note: All the baseline codes here refer to FastSpeech2, for the complete code structure, please download the official FastSpeech2, here only upload the improved code under the public model folder.
